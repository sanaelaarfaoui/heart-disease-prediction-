{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart disease prediction",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivfOnq1bW0o_",
        "outputId": "12ca5122-8ca5-4e4f-af61-39203ee8fcd2"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 79kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=80e86644d89e4853db7eb5e24e970bfa6a5fc8309bd6f35ae86faa8f760e9ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3z97Ex2RZ3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "fc82df37-cc97-465f-ddb2-243bbcc9487d"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"heart_disease\").getOrCreate()\r\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://27e770a4c769:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>heart_disease</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa1170447b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLWeS3YoTk7O",
        "outputId": "d00887d2-361d-4d84-bb22-cd9ce6d893a6"
      },
      "source": [
        "df = spark.read.csv(\"/content/heart.csv\", inferSchema=True, header=True)\r\n",
        "df.show(2)\r\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56Pfc2P-TumQ",
        "outputId": "952574bf-f172-4fa9-b10a-5fa05f2bb187"
      },
      "source": [
        "df.groupBy('target').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|target|count|\n",
            "+------+-----+\n",
            "|     1|  165|\n",
            "|     0|  138|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fHmh9qVTzGv"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler\r\n",
        "from pyspark.sql.types import * \r\n",
        "\r\n",
        "from pyspark.ml.classification import *\r\n",
        "from pyspark.ml.evaluation import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUzn_u_uUHYu"
      },
      "source": [
        "def MLClassifierDFPrep(df,input_columns,dependent_var,treat_outliers=True,treat_neg_values=True):\r\n",
        "    \r\n",
        "    renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType()))\r\n",
        "    indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\")  \r\n",
        "    indexed = indexer.fit(renamed).transform(renamed)\r\n",
        "    print(indexed.groupBy(dependent_var,\"label\").count().show(100))\r\n",
        "\r\n",
        "    \r\n",
        "    numeric_inputs = []\r\n",
        "    string_inputs = []\r\n",
        "    for column in input_columns:\r\n",
        "        if str(indexed.schema[column].dataType) == 'StringType':\r\n",
        "            indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \r\n",
        "            indexed = indexer.fit(indexed).transform(indexed)\r\n",
        "            new_col_name = column+\"_num\"\r\n",
        "            string_inputs.append(new_col_name)\r\n",
        "        else:\r\n",
        "            numeric_inputs.append(column)\r\n",
        "            \r\n",
        "    if treat_outliers == True:\r\n",
        "        print(\"We are correcting for non normality now!\")\r\n",
        "        \r\n",
        "        d = {}\r\n",
        "       \r\n",
        "        for col in numeric_inputs: \r\n",
        "            d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) \r\n",
        "      \r\n",
        "        for col in numeric_inputs:\r\n",
        "            skew = indexed.agg(skewness(indexed[col])).collect()\r\n",
        "            skew = skew[0][0]\r\n",
        "           \r\n",
        "            if skew > 1:\r\n",
        "                indexed = indexed.withColumn(col, \\\r\n",
        "                log(when(df[col] < d[col][0],d[col][0])\\\r\n",
        "                .when(indexed[col] > d[col][1], d[col][1])\\\r\n",
        "                .otherwise(indexed[col] ) +1).alias(col))\r\n",
        "                print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\r\n",
        "            elif skew < -1:\r\n",
        "                indexed = indexed.withColumn(col, \\\r\n",
        "                exp(when(df[col] < d[col][0],d[col][0])\\\r\n",
        "                .when(indexed[col] > d[col][1], d[col][1])\\\r\n",
        "                .otherwise(indexed[col] )).alias(col))\r\n",
        "                print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")\r\n",
        "\r\n",
        "            \r\n",
        "  \r\n",
        "    minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) \r\n",
        "    min_array = minimums.select(array(numeric_inputs).alias(\"mins\"))\r\n",
        "    df_minimum = min_array.select(array_min(min_array.mins)).collect() \r\n",
        "    df_minimum = df_minimum[0][0] \r\n",
        "\r\n",
        "    features_list = numeric_inputs + string_inputs\r\n",
        "    \r\n",
        "    assembler = VectorAssembler(inputCols=features_list,outputCol='features')\r\n",
        "    output = assembler.transform(indexed).select('features','label')\r\n",
        " \r\n",
        "    if df_minimum < 0:\r\n",
        "        print(\" \")\r\n",
        "        print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\r\n",
        "        print(\" \")\r\n",
        "    \r\n",
        "    if treat_neg_values == True:\r\n",
        "        print(\"You have opted to correct that by rescaling all your features to a range of 0 to 1\")\r\n",
        "        print(\" \")\r\n",
        "        print(\"We are rescaling you dataframe....\")\r\n",
        "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\r\n",
        "\r\n",
        "        scalerModel = scaler.fit(output)\r\n",
        "\r\n",
        "        scaled_data = scalerModel.transform(output)\r\n",
        "        final_data = scaled_data.select('label','scaledFeatures')\r\n",
        "        final_data = final_data.withColumnRenamed('scaledFeatures','features')\r\n",
        "        print(\"Done!\")\r\n",
        "    else:\r\n",
        "        print(\"You have opted not to correct that therefore you will not be able to use to Naive Bayes classifier\")\r\n",
        "        print(\"We will return the dataframe unscaled.\")\r\n",
        "        final_data = output\r\n",
        "    \r\n",
        "    return final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gcXfz_CUoTn"
      },
      "source": [
        "def ClassTrainEval(classifier,features,classes,folds,train,test):\r\n",
        "    \r\n",
        "    def FindMtype(classifier):\r\n",
        "        # Intstantiate Model\r\n",
        "        M = classifier\r\n",
        "        # Learn what it is\r\n",
        "        Mtype = type(M).__name__\r\n",
        "        \r\n",
        "        return Mtype\r\n",
        "    \r\n",
        "    Mtype = FindMtype(classifier)\r\n",
        "    \r\n",
        "\r\n",
        "    def IntanceFitModel(Mtype,classifier,classes,features,folds,train):\r\n",
        "        \r\n",
        "        if Mtype == \"OneVsRest\":\r\n",
        "          \r\n",
        "            lr = LogisticRegression()\r\n",
        "            OVRclassifier = OneVsRest(classifier=lr)\r\n",
        "            paramGrid = ParamGridBuilder() \\\r\n",
        "                .addGrid(lr.regParam, [0.1, 0.01]) \\\r\n",
        "                .build()\r\n",
        "            \r\n",
        "            crossval = CrossValidator(estimator=OVRclassifier,\r\n",
        "                                      estimatorParamMaps=paramGrid,\r\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\r\n",
        "                                      numFolds=folds) # 3 is best practice\r\n",
        "            \r\n",
        "            fitModel = crossval.fit(train)\r\n",
        "            return fitModel\r\n",
        "        if Mtype == \"MultilayerPerceptronClassifier\":\r\n",
        "            \r\n",
        "            features_count = len(features[0][0])\r\n",
        "            layers = [features_count, features_count+1, features_count, classes]\r\n",
        "            MPC_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\r\n",
        "            fitModel = MPC_classifier.fit(train)\r\n",
        "            return fitModel\r\n",
        "        if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2: \r\n",
        "            print(Mtype,\" could not be used because PySpark currently only accepts binary classification data for this algorithm\")\r\n",
        "            return\r\n",
        "        if Mtype in(\"LogisticRegression\",\"NaiveBayes\",\"RandomForestClassifier\",\"GBTClassifier\",\"LinearSVC\",\"DecisionTreeClassifier\"):\r\n",
        "  \r\n",
        "            \r\n",
        "            if Mtype in(\"LogisticRegression\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "\r\n",
        "                             .addGrid(classifier.maxIter, [10, 15,20])\r\n",
        "                             .build())\r\n",
        "                \r\n",
        "        \r\n",
        "            if Mtype in(\"NaiveBayes\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "                             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\r\n",
        "                             .build())\r\n",
        "         \r\n",
        "            if Mtype in(\"RandomForestClassifier\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "                               .addGrid(classifier.maxDepth, [2, 5, 10])\r\n",
        "\r\n",
        "                             .build())\r\n",
        "                \r\n",
        "          \r\n",
        "            if Mtype in(\"GBTClassifier\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "                             .addGrid(classifier.maxIter, [10, 15,50,100])\r\n",
        "                             .build())\r\n",
        "                \r\n",
        "          \r\n",
        "            if Mtype in(\"LinearSVC\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "                             .addGrid(classifier.maxIter, [10, 15]) \\\r\n",
        "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\r\n",
        "                             .build())\r\n",
        "          \r\n",
        "            if Mtype in(\"DecisionTreeClassifier\"):\r\n",
        "                paramGrid = (ParamGridBuilder() \\\r\n",
        "                             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\r\n",
        "                             .build())\r\n",
        "\r\n",
        "            crossval = CrossValidator(estimator=classifier,\r\n",
        "                                      estimatorParamMaps=paramGrid,\r\n",
        "                                      evaluator=MulticlassClassificationEvaluator(),\r\n",
        "                                      numFolds=folds) \r\n",
        "            fitModel = crossval.fit(train)\r\n",
        "            return fitModel\r\n",
        "    \r\n",
        "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,folds,train)\r\n",
        "    \r\n",
        "\r\n",
        "    if fitModel is not None:\r\n",
        "        \r\n",
        "        if Mtype in(\"OneVsRest\"):\r\n",
        "   \r\n",
        "            BestModel = fitModel.bestModel\r\n",
        "            global OVR_BestModel\r\n",
        "            OVR_BestModel = BestModel\r\n",
        "            print(\" \")\r\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\r\n",
        "\r\n",
        "            models = BestModel.models\r\n",
        "            for model in models:\r\n",
        "                print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept)\r\n",
        "                print('\\033[1m' + 'Top 20 Coefficients:'+ '\\033[0m')\r\n",
        "                coeff_array = model.coefficients.toArray()\r\n",
        "                coeff_scores = []\r\n",
        "                for x in coeff_array:\r\n",
        "                    coeff_scores.append(float(x))\r\n",
        "    \r\n",
        "                result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\r\n",
        "                print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\r\n",
        "        if Mtype == \"MultilayerPerceptronClassifier\":\r\n",
        "            print(\"\")\r\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\r\n",
        "            print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\r\n",
        "            print(\"\")\r\n",
        "            global MLPC_Model\r\n",
        "            MLPC_BestModel = fitModel\r\n",
        "\r\n",
        "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\r\n",
        "          \r\n",
        "            BestModel = fitModel.bestModel\r\n",
        "            print(\" \")\r\n",
        "            print('\\033[1m' + Mtype,\" Top 20 Feature Importances\"+ '\\033[0m')\r\n",
        "            print(\"(Scores add up to 1)\")\r\n",
        "            print(\"Lowest score is the least important\")\r\n",
        "            print(\" \")\r\n",
        "            featureImportances = BestModel.featureImportances.toArray()\r\n",
        "\r\n",
        "            imp_scores = []\r\n",
        "            for x in featureImportances:\r\n",
        "                imp_scores.append(float(x))\r\n",
        "            result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\r\n",
        "            print(result.orderBy(result[\"score\"].desc()).show(truncate=False))\r\n",
        "            if Mtype in(\"DecisionTreeClassifier\"):\r\n",
        "                global DT_featureimportances\r\n",
        "                DT_featureimportances = BestModel.featureImportances.toArray()\r\n",
        "                global DT_BestModel\r\n",
        "                DT_BestModel = BestModel\r\n",
        "            if Mtype in(\"GBTClassifier\"):\r\n",
        "                global GBT_featureimportances\r\n",
        "                GBT_featureimportances = BestModel.featureImportances.toArray()\r\n",
        "                global GBT_BestModel\r\n",
        "                GBT_BestModel = BestModel\r\n",
        "            if Mtype in(\"RandomForestClassifier\"):\r\n",
        "                global RF_featureimportances\r\n",
        "                RF_featureimportances = BestModel.featureImportances.toArray()\r\n",
        "                global RF_BestModel\r\n",
        "                RF_BestModel = BestModel\r\n",
        "\r\n",
        "        if Mtype in(\"LogisticRegression\"):\r\n",
        "            BestModel = fitModel.bestModel\r\n",
        "            print(\" \")\r\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\r\n",
        "            print(\"Intercept: \" + str(BestModel.interceptVector))\r\n",
        "            print('\\033[1m' + \" Top 20 Coefficients\"+ '\\033[0m')\r\n",
        "            print(\"You should compares these relative to eachother\")\r\n",
        "            coeff_array = BestModel.coefficientMatrix.toArray()\r\n",
        "            coeff_scores = []\r\n",
        "            for x in coeff_array[0]:\r\n",
        "                coeff_scores.append(float(x))\r\n",
        "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\r\n",
        "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\r\n",
        "            global LR_coefficients\r\n",
        "            LR_coefficients = BestModel.coefficientMatrix.toArray()\r\n",
        "            global LR_BestModel\r\n",
        "            LR_BestModel = BestModel\r\n",
        "        if Mtype in(\"LinearSVC\"):\r\n",
        "            BestModel = fitModel.bestModel\r\n",
        "            print(\" \")\r\n",
        "            print('\\033[1m' + Mtype + '\\033[0m')\r\n",
        "            print(\"Intercept: \" + str(BestModel.intercept))\r\n",
        "            print('\\033[1m' + \"Top 20 Coefficients\"+ '\\033[0m')\r\n",
        "            print(\"You should compares these relative to eachother\")\r\n",
        "\r\n",
        "            coeff_array = BestModel.coefficients.toArray()\r\n",
        "            coeff_scores = []\r\n",
        "            for x in coeff_array:\r\n",
        "                coeff_scores.append(float(x))\r\n",
        "           \r\n",
        "            result = spark.createDataFrame(zip(input_columns,coeff_scores), schema=['feature','coeff'])\r\n",
        "            print(result.orderBy(result[\"coeff\"].desc()).show(truncate=False))\r\n",
        "     \r\n",
        "            global LSVC_coefficients\r\n",
        "            LSVC_coefficients = BestModel.coefficients.toArray()\r\n",
        "            global LSVC_BestModel\r\n",
        "            LSVC_BestModel = BestModel\r\n",
        "        \r\n",
        "   \r\n",
        "   \r\n",
        "    columns = ['Classifier', 'Result']\r\n",
        "    \r\n",
        "    if Mtype in(\"LinearSVC\",\"GBTClassifier\") and classes != 2:\r\n",
        "        Mtype = [Mtype] \r\n",
        "        score = [\"N/A\"]\r\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\r\n",
        "    else:\r\n",
        "        predictions = fitModel.transform(test)\r\n",
        "        MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") \r\n",
        "        accuracy = (MC_evaluator.evaluate(predictions))*100\r\n",
        "        Mtype = [Mtype]\r\n",
        "        score = [str(accuracy)]\r\n",
        "        result = spark.createDataFrame(zip(Mtype,score), schema=columns)\r\n",
        "        result = result.withColumn('Result',result.Result.substr(0, 5))\r\n",
        "        \r\n",
        "    return result\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fac3bb04WHwk"
      },
      "source": [
        "\r\n",
        "input_columns = df.columns\r\n",
        "input_columns = input_columns[:-1] \r\n",
        "dependent_var = 'target'\r\n",
        "\r\n",
        "class_count = df.select(countDistinct(\"target\")).collect()\r\n",
        "classes = class_count[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK4ELeuZWQn9",
        "outputId": "8420fcb1-8228-484c-f0f0-54fa864c0d04"
      },
      "source": [
        "\r\n",
        "test1_data = MLClassifierDFPrep(df,input_columns,dependent_var)\r\n",
        "test1_data.limit(5).toPandas()\r\n",
        "\r\n",
        "\r\n",
        "classifiers = [\r\n",
        "                LogisticRegression()\r\n",
        "                ,OneVsRest()\r\n",
        "               ,LinearSVC()\r\n",
        "               ,NaiveBayes()\r\n",
        "               ,RandomForestClassifier()\r\n",
        "               ,GBTClassifier()\r\n",
        "               ,DecisionTreeClassifier()\r\n",
        "               ,MultilayerPerceptronClassifier()\r\n",
        "              ] \r\n",
        "\r\n",
        "train,test = test1_data.randomSplit([0.8,0.2])\r\n",
        "features = test1_data.select(['features']).collect()\r\n",
        "folds = 3 \r\n",
        "\r\n",
        "columns = ['Classifier', 'Result']\r\n",
        "vals = [(\"Place Holder\",\"N/A\")]\r\n",
        "results = spark.createDataFrame(vals, columns)\r\n",
        "\r\n",
        "for classifier in classifiers:\r\n",
        "    new_result = ClassTrainEval(classifier,features,classes,folds,train,test)\r\n",
        "    results = results.union(new_result)\r\n",
        "results = results.where(\"Classifier!='Place Holder'\")\r\n",
        "print(\"!!!!!Final Results!!!!!!!!\")\r\n",
        "results.show(100,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+-----+\n",
            "|target|label|count|\n",
            "+------+-----+-----+\n",
            "|     1|  0.0|  165|\n",
            "|     0|  1.0|  138|\n",
            "+------+-----+-----+\n",
            "\n",
            "None\n",
            "We are correcting for non normality now!\n",
            "chol has been treated for positive (right) skewness. (skew =) 1.1377326187082237 )\n",
            "fbs has been treated for positive (right) skewness. (skew =) 1.9768034646834516 )\n",
            "oldpeak has been treated for positive (right) skewness. (skew =) 1.2634255245891595 )\n",
            "ca has been treated for positive (right) skewness. (skew =) 1.303925955673585 )\n",
            "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
            " \n",
            "We are rescaling you dataframe....\n",
            "Done!\n",
            " \n",
            "\u001b[1mLogisticRegression\u001b[0m\n",
            "Intercept: [-0.3407680837231448]\n",
            "\u001b[1m Top 20 Coefficients\u001b[0m\n",
            "You should compares these relative to eachother\n",
            "+--------+--------------------+\n",
            "|feature |coeff               |\n",
            "+--------+--------------------+\n",
            "|ca      |3.420482697022333   |\n",
            "|trestbps|3.3254111711768495  |\n",
            "|thal    |2.761528949100433   |\n",
            "|sex     |1.9847438603068972  |\n",
            "|chol    |1.6743548113856381  |\n",
            "|oldpeak |1.3556770829294473  |\n",
            "|exang   |0.8250140862397598  |\n",
            "|fbs     |-0.16291024841459398|\n",
            "|restecg |-1.233464554330648  |\n",
            "|slope   |-1.3784337227795798 |\n",
            "|age     |-1.4253874918135643 |\n",
            "|cp      |-2.8822662475951093 |\n",
            "|thalach |-5.739021564915195  |\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mOneVsRest\u001b[0m\n",
            "\u001b[1mIntercept: \u001b[0m 2.2960238684058583\n",
            "\u001b[1mTop 20 Coefficients:\u001b[0m\n",
            "+--------+-------------------+\n",
            "|feature |coeff              |\n",
            "+--------+-------------------+\n",
            "|thalach |3.8085883352174283 |\n",
            "|cp      |2.3346441007577363 |\n",
            "|slope   |0.9395446390482376 |\n",
            "|restecg |0.8640778598104573 |\n",
            "|age     |0.38114444314294876|\n",
            "|fbs     |0.12197406261166828|\n",
            "|exang   |-0.8708144726087023|\n",
            "|oldpeak |-1.4771564046994634|\n",
            "|sex     |-1.7464582773436017|\n",
            "|chol    |-1.799760100539453 |\n",
            "|trestbps|-2.466388712710661 |\n",
            "|thal    |-2.7969243453074544|\n",
            "|ca      |-2.8259703801346716|\n",
            "+--------+-------------------+\n",
            "\n",
            "None\n",
            "\u001b[1mIntercept: \u001b[0m -2.296023868375282\n",
            "\u001b[1mTop 20 Coefficients:\u001b[0m\n",
            "+--------+--------------------+\n",
            "|feature |coeff               |\n",
            "+--------+--------------------+\n",
            "|ca      |2.825970380135645   |\n",
            "|thal    |2.796924345301244   |\n",
            "|trestbps|2.4663887126978423  |\n",
            "|chol    |1.7997601005284798  |\n",
            "|sex     |1.7464582773383641  |\n",
            "|oldpeak |1.477156404685712   |\n",
            "|exang   |0.8708144726101139  |\n",
            "|fbs     |-0.12197406261133621|\n",
            "|age     |-0.3811444431446033 |\n",
            "|restecg |-0.8640778598085223 |\n",
            "|slope   |-0.9395446390689809 |\n",
            "|cp      |-2.334644100754984  |\n",
            "|thalach |-3.8085883352105028 |\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mLinearSVC\u001b[0m\n",
            "Intercept: -0.016617310178779057\n",
            "\u001b[1mTop 20 Coefficients\u001b[0m\n",
            "You should compares these relative to eachother\n",
            "+--------+--------------------+\n",
            "|feature |coeff               |\n",
            "+--------+--------------------+\n",
            "|ca      |1.3090469097800497  |\n",
            "|thal    |1.1434992849398589  |\n",
            "|oldpeak |0.8791083439298922  |\n",
            "|exang   |0.5816027453721181  |\n",
            "|sex     |0.5621168610934674  |\n",
            "|trestbps|0.5118926873631289  |\n",
            "|fbs     |0.04597686913787795 |\n",
            "|age     |-0.06446418380053198|\n",
            "|chol    |-0.11826981706409283|\n",
            "|restecg |-0.457179689255327  |\n",
            "|slope   |-0.8223246711147744 |\n",
            "|cp      |-1.1697207350656782 |\n",
            "|thalach |-2.1625778251271957 |\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mRandomForestClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+--------+-------------------+\n",
            "|feature |score              |\n",
            "+--------+-------------------+\n",
            "|cp      |0.16440982777826568|\n",
            "|thalach |0.14853894267047363|\n",
            "|ca      |0.13854415837961248|\n",
            "|thal    |0.10392228397489618|\n",
            "|oldpeak |0.10324764174327487|\n",
            "|exang   |0.07149898493964603|\n",
            "|trestbps|0.06638332134205385|\n",
            "|age     |0.06282249331052743|\n",
            "|chol    |0.05622988463646165|\n",
            "|slope   |0.04075869478467253|\n",
            "|sex     |0.02139571239894871|\n",
            "|restecg |0.01769048409924038|\n",
            "|fbs     |0.0045575699419266 |\n",
            "+--------+-------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mGBTClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+--------+--------------------+\n",
            "|feature |score               |\n",
            "+--------+--------------------+\n",
            "|age     |0.16247101690902344 |\n",
            "|cp      |0.1421737172294599  |\n",
            "|thalach |0.1293873735453533  |\n",
            "|ca      |0.11757809335054349 |\n",
            "|chol    |0.10815645328168129 |\n",
            "|oldpeak |0.09150475407333665 |\n",
            "|thal    |0.0776748999939759  |\n",
            "|trestbps|0.06662481845044015 |\n",
            "|sex     |0.0441101769937118  |\n",
            "|restecg |0.029102984356654826|\n",
            "|slope   |0.014024325065542622|\n",
            "|exang   |0.011666409255475556|\n",
            "|fbs     |0.005524977494801057|\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            " \n",
            "\u001b[1mDecisionTreeClassifier  Top 20 Feature Importances\u001b[0m\n",
            "(Scores add up to 1)\n",
            "Lowest score is the least important\n",
            " \n",
            "+--------+--------------------+\n",
            "|feature |score               |\n",
            "+--------+--------------------+\n",
            "|cp      |0.33343473763064113 |\n",
            "|thal    |0.16283474584089924 |\n",
            "|ca      |0.1409661360299031  |\n",
            "|trestbps|0.0821751777935077  |\n",
            "|age     |0.05846159428697557 |\n",
            "|oldpeak |0.043971798764830525|\n",
            "|sex     |0.04277098612659772 |\n",
            "|chol    |0.04140566961115182 |\n",
            "|restecg |0.040148164089627916|\n",
            "|thalach |0.039002150220111324|\n",
            "|fbs     |0.014828839605753935|\n",
            "|exang   |0.0                 |\n",
            "|slope   |0.0                 |\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            "\n",
            "\u001b[1mMultilayerPerceptronClassifier\u001b[0m\n",
            "\u001b[1mModel Weights: \u001b[0m 419\n",
            "\n",
            "!!!!!Final Results!!!!!!!!\n",
            "+------------------------------+------+\n",
            "|Classifier                    |Result|\n",
            "+------------------------------+------+\n",
            "|LogisticRegression            |86.44 |\n",
            "|OneVsRest                     |86.44 |\n",
            "|LinearSVC                     |86.44 |\n",
            "|NaiveBayes                    |86.44 |\n",
            "|RandomForestClassifier        |86.44 |\n",
            "|GBTClassifier                 |86.44 |\n",
            "|DecisionTreeClassifier        |77.96 |\n",
            "|MultilayerPerceptronClassifier|77.96 |\n",
            "+------------------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCE0QtnrWVDu"
      },
      "source": [
        "predictions = LR_BestModel.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BR3c3fCWYzW",
        "outputId": "6f89db36-2792-4876-e134-d18f56c4b02c"
      },
      "source": [
        "predictions.filter(\"prediction==1\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|[0.47916666666666...|[-2.3713578842561...|[0.08538303876592...|       1.0|\n",
            "|  0.0|[0.5,1.0,0.0,0.45...|[-3.5443308343590...|[0.02807686391202...|       1.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYz8hmD4WayO",
        "outputId": "02e165f0-efce-4986-8638-acd77e4e0951"
      },
      "source": [
        "predictions.groupBy(\"label\").count().show()\r\n",
        "predictions.groupBy(\"prediction\").count().show()\r\n",
        "\r\n",
        "predictions.filter(\"prediction != label\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|   34|\n",
            "|  1.0|   25|\n",
            "+-----+-----+\n",
            "\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0|   32|\n",
            "|       1.0|   27|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5-_pC-IWdDX",
        "outputId": "e11c6e4f-5c36-4968-9cd8-2c8fbc60a4e4"
      },
      "source": [
        "from pyspark.ml.feature import VectorSlicer\r\n",
        "from pyspark.ml.feature import ChiSqSelector\r\n",
        "from pyspark.ml.linalg import Vectors\r\n",
        "\r\n",
        "classifiers = [ LogisticRegression()\r\n",
        "                ] \r\n",
        "n = 99\r\n",
        "\r\n",
        "selector = ChiSqSelector(numTopFeatures=n, featuresCol=\"features\",\r\n",
        "                     outputCol=\"selectedFeatures\", labelCol=\"label\")\r\n",
        "bestFeaturesDf = selector.fit(test1_data).transform(test1_data)\r\n",
        "bestFeaturesDf = bestFeaturesDf.select(\"label\",\"selectedFeatures\")\r\n",
        "bestFeaturesDf = bestFeaturesDf.withColumnRenamed(\"selectedFeatures\",\"features\")\r\n",
        "\r\n",
        "features = bestFeaturesDf.select(['features']).collect()\r\n",
        "\r\n",
        "train,test = bestFeaturesDf.randomSplit([0.8,0.2])\r\n",
        "\r\n",
        "folds = 3\r\n",
        "\r\n",
        "columns = ['Classifier', 'Result']\r\n",
        "vals = [(\"Place Holder\",\"N/A\")]\r\n",
        "results = spark.createDataFrame(vals, columns)\r\n",
        "\r\n",
        "for classifier in classifiers:\r\n",
        "    new_result = ClassTrainEval(classifier,features,classes,folds,train,test)\r\n",
        "    results = results.union(new_result)\r\n",
        "results = results.where(\"Classifier!='Place Holder'\")\r\n",
        "results.show(100,False)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            "\u001b[1mLogisticRegression\u001b[0m\n",
            "Intercept: [-1.2241230117936226]\n",
            "\u001b[1m Top 20 Coefficients\u001b[0m\n",
            "You should compares these relative to eachother\n",
            "+--------+--------------------+\n",
            "|feature |coeff               |\n",
            "+--------+--------------------+\n",
            "|ca      |3.342905220479936   |\n",
            "|trestbps|2.8410007940402098  |\n",
            "|thal    |2.3728834121424085  |\n",
            "|chol    |1.6901700702041635  |\n",
            "|sex     |1.427428712671764   |\n",
            "|exang   |1.156599991524827   |\n",
            "|oldpeak |1.120787406235372   |\n",
            "|fbs     |-0.20321189952707713|\n",
            "|age     |-0.9676058003747318 |\n",
            "|restecg |-1.0465928960272672 |\n",
            "|slope   |-2.2309936454218944 |\n",
            "|cp      |-2.6801351887959175 |\n",
            "|thalach |-3.0927961865980866 |\n",
            "+--------+--------------------+\n",
            "\n",
            "None\n",
            "+------------------+------+\n",
            "|Classifier        |Result|\n",
            "+------------------+------+\n",
            "|LogisticRegression|82.53 |\n",
            "+------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}